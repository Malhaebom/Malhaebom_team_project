{
  "best_global_step": 3096,
  "best_metric": 55.8584894404009,
  "best_model_checkpoint": "./whisper-small-ko-dialect-final\\checkpoint-3096",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3096,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016152479405588758,
      "grad_norm": 7.073124885559082,
      "learning_rate": 4.800000000000001e-06,
      "loss": 3.2124,
      "step": 25
    },
    {
      "epoch": 0.032304958811177516,
      "grad_norm": 8.297320365905762,
      "learning_rate": 9.800000000000001e-06,
      "loss": 3.1699,
      "step": 50
    },
    {
      "epoch": 0.04845743821676628,
      "grad_norm": 8.683755874633789,
      "learning_rate": 9.947757945145843e-06,
      "loss": 2.743,
      "step": 75
    },
    {
      "epoch": 0.06460991762235503,
      "grad_norm": 5.906506538391113,
      "learning_rate": 9.893339138006096e-06,
      "loss": 2.4318,
      "step": 100
    },
    {
      "epoch": 0.08076239702794379,
      "grad_norm": 3.6429083347320557,
      "learning_rate": 9.838920330866348e-06,
      "loss": 2.165,
      "step": 125
    },
    {
      "epoch": 0.09691487643353255,
      "grad_norm": 2.0205585956573486,
      "learning_rate": 9.7845015237266e-06,
      "loss": 1.9678,
      "step": 150
    },
    {
      "epoch": 0.11306735583912131,
      "grad_norm": 1.5493746995925903,
      "learning_rate": 9.730082716586852e-06,
      "loss": 1.9297,
      "step": 175
    },
    {
      "epoch": 0.12921983524471006,
      "grad_norm": 1.1099951267242432,
      "learning_rate": 9.675663909447105e-06,
      "loss": 1.7557,
      "step": 200
    },
    {
      "epoch": 0.14537231465029882,
      "grad_norm": 1.1132690906524658,
      "learning_rate": 9.621245102307358e-06,
      "loss": 1.7359,
      "step": 225
    },
    {
      "epoch": 0.16152479405588757,
      "grad_norm": 1.22081458568573,
      "learning_rate": 9.56682629516761e-06,
      "loss": 1.6662,
      "step": 250
    },
    {
      "epoch": 0.17767727346147633,
      "grad_norm": 1.370103120803833,
      "learning_rate": 9.512407488027863e-06,
      "loss": 1.6187,
      "step": 275
    },
    {
      "epoch": 0.1938297528670651,
      "grad_norm": 1.240044116973877,
      "learning_rate": 9.457988680888116e-06,
      "loss": 1.4957,
      "step": 300
    },
    {
      "epoch": 0.20998223227265386,
      "grad_norm": 1.1540478467941284,
      "learning_rate": 9.403569873748368e-06,
      "loss": 1.4591,
      "step": 325
    },
    {
      "epoch": 0.22613471167824262,
      "grad_norm": 1.3703526258468628,
      "learning_rate": 9.34915106660862e-06,
      "loss": 1.3572,
      "step": 350
    },
    {
      "epoch": 0.24228719108383137,
      "grad_norm": 1.0270029306411743,
      "learning_rate": 9.294732259468872e-06,
      "loss": 1.277,
      "step": 375
    },
    {
      "epoch": 0.2584396704894201,
      "grad_norm": 0.8510879278182983,
      "learning_rate": 9.240313452329125e-06,
      "loss": 1.305,
      "step": 400
    },
    {
      "epoch": 0.2745921498950089,
      "grad_norm": 0.965860903263092,
      "learning_rate": 9.185894645189378e-06,
      "loss": 1.2822,
      "step": 425
    },
    {
      "epoch": 0.29074462930059763,
      "grad_norm": 0.8969771862030029,
      "learning_rate": 9.13147583804963e-06,
      "loss": 1.3034,
      "step": 450
    },
    {
      "epoch": 0.3068971087061864,
      "grad_norm": 1.0304368734359741,
      "learning_rate": 9.077057030909883e-06,
      "loss": 1.2855,
      "step": 475
    },
    {
      "epoch": 0.32304958811177514,
      "grad_norm": 0.858117401599884,
      "learning_rate": 9.022638223770136e-06,
      "loss": 1.2971,
      "step": 500
    },
    {
      "epoch": 0.3392020675173639,
      "grad_norm": 0.9159199595451355,
      "learning_rate": 8.968219416630387e-06,
      "loss": 1.2132,
      "step": 525
    },
    {
      "epoch": 0.35535454692295265,
      "grad_norm": 1.021944284439087,
      "learning_rate": 8.91380060949064e-06,
      "loss": 1.2345,
      "step": 550
    },
    {
      "epoch": 0.37150702632854143,
      "grad_norm": 1.00606369972229,
      "learning_rate": 8.859381802350894e-06,
      "loss": 1.2162,
      "step": 575
    },
    {
      "epoch": 0.3876595057341302,
      "grad_norm": 0.9872648119926453,
      "learning_rate": 8.804962995211147e-06,
      "loss": 1.1657,
      "step": 600
    },
    {
      "epoch": 0.40381198513971894,
      "grad_norm": 1.013954997062683,
      "learning_rate": 8.750544188071398e-06,
      "loss": 1.1819,
      "step": 625
    },
    {
      "epoch": 0.4199644645453077,
      "grad_norm": 1.0638431310653687,
      "learning_rate": 8.69612538093165e-06,
      "loss": 1.197,
      "step": 650
    },
    {
      "epoch": 0.43611694395089645,
      "grad_norm": 0.9995981454849243,
      "learning_rate": 8.641706573791904e-06,
      "loss": 1.1883,
      "step": 675
    },
    {
      "epoch": 0.45226942335648523,
      "grad_norm": 1.303335428237915,
      "learning_rate": 8.587287766652156e-06,
      "loss": 1.1398,
      "step": 700
    },
    {
      "epoch": 0.46842190276207396,
      "grad_norm": 0.9451339840888977,
      "learning_rate": 8.532868959512407e-06,
      "loss": 1.1648,
      "step": 725
    },
    {
      "epoch": 0.48457438216766274,
      "grad_norm": 1.3923542499542236,
      "learning_rate": 8.47845015237266e-06,
      "loss": 1.1341,
      "step": 750
    },
    {
      "epoch": 0.5007268615732515,
      "grad_norm": 0.9388210773468018,
      "learning_rate": 8.424031345232914e-06,
      "loss": 1.1472,
      "step": 775
    },
    {
      "epoch": 0.5168793409788403,
      "grad_norm": 1.0663667917251587,
      "learning_rate": 8.369612538093167e-06,
      "loss": 1.1511,
      "step": 800
    },
    {
      "epoch": 0.533031820384429,
      "grad_norm": 0.9897066354751587,
      "learning_rate": 8.315193730953418e-06,
      "loss": 1.1355,
      "step": 825
    },
    {
      "epoch": 0.5491842997900178,
      "grad_norm": 1.0299720764160156,
      "learning_rate": 8.26077492381367e-06,
      "loss": 1.133,
      "step": 850
    },
    {
      "epoch": 0.5653367791956065,
      "grad_norm": 1.2510541677474976,
      "learning_rate": 8.206356116673924e-06,
      "loss": 1.1368,
      "step": 875
    },
    {
      "epoch": 0.5814892586011953,
      "grad_norm": 1.0173295736312866,
      "learning_rate": 8.151937309534176e-06,
      "loss": 1.1026,
      "step": 900
    },
    {
      "epoch": 0.597641738006784,
      "grad_norm": 1.055578351020813,
      "learning_rate": 8.097518502394427e-06,
      "loss": 1.1371,
      "step": 925
    },
    {
      "epoch": 0.6137942174123728,
      "grad_norm": 0.9462383389472961,
      "learning_rate": 8.04309969525468e-06,
      "loss": 1.0962,
      "step": 950
    },
    {
      "epoch": 0.6299466968179616,
      "grad_norm": 1.1263726949691772,
      "learning_rate": 7.988680888114933e-06,
      "loss": 1.1198,
      "step": 975
    },
    {
      "epoch": 0.6460991762235503,
      "grad_norm": 1.2718322277069092,
      "learning_rate": 7.934262080975187e-06,
      "loss": 1.0971,
      "step": 1000
    },
    {
      "epoch": 0.6622516556291391,
      "grad_norm": 1.1933115720748901,
      "learning_rate": 7.879843273835438e-06,
      "loss": 1.0837,
      "step": 1025
    },
    {
      "epoch": 0.6784041350347279,
      "grad_norm": 1.1332837343215942,
      "learning_rate": 7.82542446669569e-06,
      "loss": 1.0989,
      "step": 1050
    },
    {
      "epoch": 0.6945566144403166,
      "grad_norm": 0.936959445476532,
      "learning_rate": 7.771005659555944e-06,
      "loss": 1.099,
      "step": 1075
    },
    {
      "epoch": 0.7107090938459053,
      "grad_norm": 1.2215752601623535,
      "learning_rate": 7.716586852416196e-06,
      "loss": 1.0787,
      "step": 1100
    },
    {
      "epoch": 0.7268615732514941,
      "grad_norm": 1.3113479614257812,
      "learning_rate": 7.662168045276449e-06,
      "loss": 1.0864,
      "step": 1125
    },
    {
      "epoch": 0.7430140526570829,
      "grad_norm": 1.094253659248352,
      "learning_rate": 7.6077492381367e-06,
      "loss": 1.091,
      "step": 1150
    },
    {
      "epoch": 0.7591665320626716,
      "grad_norm": 1.1014324426651,
      "learning_rate": 7.553330430996953e-06,
      "loss": 1.1022,
      "step": 1175
    },
    {
      "epoch": 0.7753190114682604,
      "grad_norm": 1.2302089929580688,
      "learning_rate": 7.498911623857206e-06,
      "loss": 1.1024,
      "step": 1200
    },
    {
      "epoch": 0.7914714908738492,
      "grad_norm": 1.078302025794983,
      "learning_rate": 7.444492816717458e-06,
      "loss": 1.0989,
      "step": 1225
    },
    {
      "epoch": 0.8076239702794379,
      "grad_norm": 1.1252436637878418,
      "learning_rate": 7.39007400957771e-06,
      "loss": 1.1173,
      "step": 1250
    },
    {
      "epoch": 0.8237764496850266,
      "grad_norm": 1.13041353225708,
      "learning_rate": 7.335655202437963e-06,
      "loss": 1.0941,
      "step": 1275
    },
    {
      "epoch": 0.8399289290906155,
      "grad_norm": 0.9139906764030457,
      "learning_rate": 7.2812363952982156e-06,
      "loss": 1.0663,
      "step": 1300
    },
    {
      "epoch": 0.8560814084962042,
      "grad_norm": 1.2408888339996338,
      "learning_rate": 7.226817588158468e-06,
      "loss": 1.1158,
      "step": 1325
    },
    {
      "epoch": 0.8722338879017929,
      "grad_norm": 1.1896917819976807,
      "learning_rate": 7.17239878101872e-06,
      "loss": 1.1028,
      "step": 1350
    },
    {
      "epoch": 0.8883863673073816,
      "grad_norm": 1.7892709970474243,
      "learning_rate": 7.117979973878973e-06,
      "loss": 1.0711,
      "step": 1375
    },
    {
      "epoch": 0.9045388467129705,
      "grad_norm": 1.255080223083496,
      "learning_rate": 7.0635611667392255e-06,
      "loss": 1.0906,
      "step": 1400
    },
    {
      "epoch": 0.9206913261185592,
      "grad_norm": 0.8457286357879639,
      "learning_rate": 7.009142359599478e-06,
      "loss": 1.0857,
      "step": 1425
    },
    {
      "epoch": 0.9368438055241479,
      "grad_norm": 1.5074540376663208,
      "learning_rate": 6.954723552459731e-06,
      "loss": 1.0916,
      "step": 1450
    },
    {
      "epoch": 0.9529962849297368,
      "grad_norm": 1.2666562795639038,
      "learning_rate": 6.900304745319983e-06,
      "loss": 1.0867,
      "step": 1475
    },
    {
      "epoch": 0.9691487643353255,
      "grad_norm": 1.3224091529846191,
      "learning_rate": 6.8458859381802355e-06,
      "loss": 1.0716,
      "step": 1500
    },
    {
      "epoch": 0.9853012437409142,
      "grad_norm": 1.3347316980361938,
      "learning_rate": 6.791467131040488e-06,
      "loss": 1.058,
      "step": 1525
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.0703874826431274,
      "eval_runtime": 15343.0057,
      "eval_samples_per_second": 0.177,
      "eval_steps_per_second": 0.044,
      "eval_wer": 73.68094499463072,
      "step": 1548
    },
    {
      "epoch": 1.0012921983524472,
      "grad_norm": 1.042474389076233,
      "learning_rate": 6.737048323900741e-06,
      "loss": 1.0863,
      "step": 1550
    },
    {
      "epoch": 1.017444677758036,
      "grad_norm": 1.13773512840271,
      "learning_rate": 6.682629516760993e-06,
      "loss": 1.0825,
      "step": 1575
    },
    {
      "epoch": 1.0335971571636247,
      "grad_norm": 1.005823016166687,
      "learning_rate": 6.628210709621245e-06,
      "loss": 1.0789,
      "step": 1600
    },
    {
      "epoch": 1.0497496365692134,
      "grad_norm": 1.2023502588272095,
      "learning_rate": 6.573791902481498e-06,
      "loss": 1.0666,
      "step": 1625
    },
    {
      "epoch": 1.0659021159748021,
      "grad_norm": 1.0488629341125488,
      "learning_rate": 6.519373095341751e-06,
      "loss": 1.0798,
      "step": 1650
    },
    {
      "epoch": 1.0820545953803908,
      "grad_norm": 0.9685502052307129,
      "learning_rate": 6.464954288202003e-06,
      "loss": 1.0527,
      "step": 1675
    },
    {
      "epoch": 1.0982070747859796,
      "grad_norm": 1.1918776035308838,
      "learning_rate": 6.410535481062255e-06,
      "loss": 1.062,
      "step": 1700
    },
    {
      "epoch": 1.1143595541915685,
      "grad_norm": 1.1402252912521362,
      "learning_rate": 6.356116673922508e-06,
      "loss": 1.0693,
      "step": 1725
    },
    {
      "epoch": 1.1305120335971572,
      "grad_norm": 1.131622314453125,
      "learning_rate": 6.301697866782761e-06,
      "loss": 1.071,
      "step": 1750
    },
    {
      "epoch": 1.146664513002746,
      "grad_norm": 1.003456473350525,
      "learning_rate": 6.247279059643013e-06,
      "loss": 1.0443,
      "step": 1775
    },
    {
      "epoch": 1.1628169924083347,
      "grad_norm": 1.1325709819793701,
      "learning_rate": 6.192860252503265e-06,
      "loss": 1.0471,
      "step": 1800
    },
    {
      "epoch": 1.1789694718139234,
      "grad_norm": 0.9524211287498474,
      "learning_rate": 6.138441445363518e-06,
      "loss": 1.0417,
      "step": 1825
    },
    {
      "epoch": 1.1951219512195121,
      "grad_norm": 1.1968318223953247,
      "learning_rate": 6.084022638223771e-06,
      "loss": 1.0838,
      "step": 1850
    },
    {
      "epoch": 1.2112744306251009,
      "grad_norm": 0.9525485634803772,
      "learning_rate": 6.029603831084023e-06,
      "loss": 1.0714,
      "step": 1875
    },
    {
      "epoch": 1.2274269100306898,
      "grad_norm": 1.0523021221160889,
      "learning_rate": 5.975185023944275e-06,
      "loss": 1.0471,
      "step": 1900
    },
    {
      "epoch": 1.2435793894362785,
      "grad_norm": 0.8551168441772461,
      "learning_rate": 5.9207662168045275e-06,
      "loss": 1.033,
      "step": 1925
    },
    {
      "epoch": 1.2597318688418673,
      "grad_norm": 1.172122836112976,
      "learning_rate": 5.866347409664781e-06,
      "loss": 1.0745,
      "step": 1950
    },
    {
      "epoch": 1.275884348247456,
      "grad_norm": 1.0959243774414062,
      "learning_rate": 5.811928602525033e-06,
      "loss": 1.0552,
      "step": 1975
    },
    {
      "epoch": 1.2920368276530447,
      "grad_norm": 1.1315572261810303,
      "learning_rate": 5.757509795385285e-06,
      "loss": 1.0576,
      "step": 2000
    },
    {
      "epoch": 1.3081893070586335,
      "grad_norm": 1.1417992115020752,
      "learning_rate": 5.7030909882455375e-06,
      "loss": 1.0898,
      "step": 2025
    },
    {
      "epoch": 1.3243417864642222,
      "grad_norm": 1.059859275817871,
      "learning_rate": 5.648672181105791e-06,
      "loss": 1.0459,
      "step": 2050
    },
    {
      "epoch": 1.3404942658698111,
      "grad_norm": 1.053041934967041,
      "learning_rate": 5.594253373966043e-06,
      "loss": 1.0137,
      "step": 2075
    },
    {
      "epoch": 1.3566467452753999,
      "grad_norm": 1.0535274744033813,
      "learning_rate": 5.539834566826295e-06,
      "loss": 1.0297,
      "step": 2100
    },
    {
      "epoch": 1.3727992246809886,
      "grad_norm": 1.244498372077942,
      "learning_rate": 5.4854157596865474e-06,
      "loss": 1.0557,
      "step": 2125
    },
    {
      "epoch": 1.3889517040865773,
      "grad_norm": 1.2681273221969604,
      "learning_rate": 5.4309969525468006e-06,
      "loss": 1.0373,
      "step": 2150
    },
    {
      "epoch": 1.405104183492166,
      "grad_norm": 1.1264026165008545,
      "learning_rate": 5.376578145407053e-06,
      "loss": 1.046,
      "step": 2175
    },
    {
      "epoch": 1.4212566628977548,
      "grad_norm": 1.2587785720825195,
      "learning_rate": 5.322159338267305e-06,
      "loss": 1.0218,
      "step": 2200
    },
    {
      "epoch": 1.4374091423033435,
      "grad_norm": 0.9594078660011292,
      "learning_rate": 5.267740531127557e-06,
      "loss": 1.0493,
      "step": 2225
    },
    {
      "epoch": 1.4535616217089324,
      "grad_norm": 0.9706791043281555,
      "learning_rate": 5.2133217239878105e-06,
      "loss": 1.0274,
      "step": 2250
    },
    {
      "epoch": 1.469714101114521,
      "grad_norm": 1.0073333978652954,
      "learning_rate": 5.158902916848063e-06,
      "loss": 1.0311,
      "step": 2275
    },
    {
      "epoch": 1.48586658052011,
      "grad_norm": 1.052353024482727,
      "learning_rate": 5.104484109708315e-06,
      "loss": 1.0197,
      "step": 2300
    },
    {
      "epoch": 1.5020190599256986,
      "grad_norm": 0.9761741161346436,
      "learning_rate": 5.050065302568569e-06,
      "loss": 1.0558,
      "step": 2325
    },
    {
      "epoch": 1.5181715393312873,
      "grad_norm": 1.1714175939559937,
      "learning_rate": 4.9956464954288205e-06,
      "loss": 1.0239,
      "step": 2350
    },
    {
      "epoch": 1.534324018736876,
      "grad_norm": 1.079101324081421,
      "learning_rate": 4.941227688289073e-06,
      "loss": 1.0229,
      "step": 2375
    },
    {
      "epoch": 1.5504764981424648,
      "grad_norm": 1.2007919549942017,
      "learning_rate": 4.886808881149326e-06,
      "loss": 1.0244,
      "step": 2400
    },
    {
      "epoch": 1.5666289775480537,
      "grad_norm": 1.255920648574829,
      "learning_rate": 4.832390074009578e-06,
      "loss": 1.0188,
      "step": 2425
    },
    {
      "epoch": 1.5827814569536423,
      "grad_norm": 0.8790697455406189,
      "learning_rate": 4.77797126686983e-06,
      "loss": 1.018,
      "step": 2450
    },
    {
      "epoch": 1.5989339363592312,
      "grad_norm": 1.03313148021698,
      "learning_rate": 4.723552459730083e-06,
      "loss": 1.0388,
      "step": 2475
    },
    {
      "epoch": 1.61508641576482,
      "grad_norm": 1.0176680088043213,
      "learning_rate": 4.669133652590336e-06,
      "loss": 1.0582,
      "step": 2500
    },
    {
      "epoch": 1.6312388951704087,
      "grad_norm": 1.1121901273727417,
      "learning_rate": 4.614714845450588e-06,
      "loss": 1.0763,
      "step": 2525
    },
    {
      "epoch": 1.6473913745759974,
      "grad_norm": 1.2419267892837524,
      "learning_rate": 4.560296038310841e-06,
      "loss": 1.0436,
      "step": 2550
    },
    {
      "epoch": 1.663543853981586,
      "grad_norm": 1.088181495666504,
      "learning_rate": 4.505877231171093e-06,
      "loss": 1.044,
      "step": 2575
    },
    {
      "epoch": 1.679696333387175,
      "grad_norm": 1.1054755449295044,
      "learning_rate": 4.451458424031346e-06,
      "loss": 1.0408,
      "step": 2600
    },
    {
      "epoch": 1.6958488127927636,
      "grad_norm": 1.0285041332244873,
      "learning_rate": 4.397039616891598e-06,
      "loss": 1.0578,
      "step": 2625
    },
    {
      "epoch": 1.7120012921983525,
      "grad_norm": 1.052338719367981,
      "learning_rate": 4.342620809751851e-06,
      "loss": 1.0553,
      "step": 2650
    },
    {
      "epoch": 1.7281537716039412,
      "grad_norm": 1.135183334350586,
      "learning_rate": 4.2882020026121026e-06,
      "loss": 1.0258,
      "step": 2675
    },
    {
      "epoch": 1.74430625100953,
      "grad_norm": 1.1365020275115967,
      "learning_rate": 4.233783195472356e-06,
      "loss": 1.0002,
      "step": 2700
    },
    {
      "epoch": 1.7604587304151187,
      "grad_norm": 0.9694841504096985,
      "learning_rate": 4.179364388332608e-06,
      "loss": 1.0473,
      "step": 2725
    },
    {
      "epoch": 1.7766112098207074,
      "grad_norm": 1.1537128686904907,
      "learning_rate": 4.124945581192861e-06,
      "loss": 1.0107,
      "step": 2750
    },
    {
      "epoch": 1.7927636892262964,
      "grad_norm": 1.1740740537643433,
      "learning_rate": 4.0705267740531125e-06,
      "loss": 0.9925,
      "step": 2775
    },
    {
      "epoch": 1.8089161686318849,
      "grad_norm": 1.2050517797470093,
      "learning_rate": 4.016107966913366e-06,
      "loss": 1.0399,
      "step": 2800
    },
    {
      "epoch": 1.8250686480374738,
      "grad_norm": 1.2237828969955444,
      "learning_rate": 3.961689159773618e-06,
      "loss": 1.034,
      "step": 2825
    },
    {
      "epoch": 1.8412211274430625,
      "grad_norm": 1.1872984170913696,
      "learning_rate": 3.907270352633871e-06,
      "loss": 1.0237,
      "step": 2850
    },
    {
      "epoch": 1.8573736068486513,
      "grad_norm": 1.5119084119796753,
      "learning_rate": 3.8528515454941225e-06,
      "loss": 1.088,
      "step": 2875
    },
    {
      "epoch": 1.87352608625424,
      "grad_norm": 2.1944503784179688,
      "learning_rate": 3.7984327383543756e-06,
      "loss": 1.071,
      "step": 2900
    },
    {
      "epoch": 1.8896785656598287,
      "grad_norm": 1.0886512994766235,
      "learning_rate": 3.744013931214628e-06,
      "loss": 1.0384,
      "step": 2925
    },
    {
      "epoch": 1.9058310450654177,
      "grad_norm": 1.0471915006637573,
      "learning_rate": 3.6895951240748806e-06,
      "loss": 1.0545,
      "step": 2950
    },
    {
      "epoch": 1.9219835244710062,
      "grad_norm": 1.1321334838867188,
      "learning_rate": 3.635176316935133e-06,
      "loss": 1.0084,
      "step": 2975
    },
    {
      "epoch": 1.9381360038765951,
      "grad_norm": 1.2960484027862549,
      "learning_rate": 3.5807575097953855e-06,
      "loss": 1.0491,
      "step": 3000
    },
    {
      "epoch": 1.9542884832821839,
      "grad_norm": 12.554054260253906,
      "learning_rate": 3.526338702655638e-06,
      "loss": 1.0471,
      "step": 3025
    },
    {
      "epoch": 1.9704409626877726,
      "grad_norm": 1.3194531202316284,
      "learning_rate": 3.4719198955158905e-06,
      "loss": 1.0632,
      "step": 3050
    },
    {
      "epoch": 1.9865934420933613,
      "grad_norm": 1.4668406248092651,
      "learning_rate": 3.417501088376143e-06,
      "loss": 1.0778,
      "step": 3075
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.0270071029663086,
      "eval_runtime": 13771.7213,
      "eval_samples_per_second": 0.197,
      "eval_steps_per_second": 0.049,
      "eval_wer": 55.8584894404009,
      "step": 3096
    }
  ],
  "logging_steps": 25,
  "max_steps": 4644,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.435441820516352e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
